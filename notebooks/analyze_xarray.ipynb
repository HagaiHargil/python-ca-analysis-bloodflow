{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script takes an `xarray` Dataset that was generated from analysis of Calium data, and writes it to disk in such a way that it can be read and post-processed by `R` scripts which test the statistical significance of the different activity of two groups or more, with knowledge of the mouse ID that generated this data. Or in other words - ANOVA with a nested design. These functions currently don't exist in Python, which is why it had to be done in R.\n",
    "\n",
    "The R scripts as well as this one are currently optimized for Amit's FMR-WT data, but that should be easily changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "import pathlib\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from calcium_bflow_analysis.single_fov_analysis import filter_da\n",
    "from calcium_bflow_analysis.dff_analysis_and_plotting import dff_analysis\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[PosixPath('/data/Amit_QNAP/Calcium_FXS/data_of_day_1.nc')]"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foldername = pathlib.Path('/data/Amit_QNAP/Calcium_FXS/')\n",
    "fname_glob = '*.nc'\n",
    "full_fnames = list(foldername.glob(fname_glob))\n",
    "full_fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.open_dataset(full_fnames[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now build a dictionary which divides the data into the different groupings. We'll pickle it to avoid running everything everytime, but besides that the dictionary is a helper variable that lets us construct specific dataframes containing only the relevant data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "dF/F shape of mouse 293 in epoch spont contained too few rows.\ndF/F shape of mouse 293 in epoch stim contained too few rows.\ndF/F shape of mouse 293 in epoch all contained too few rows.\ndF/F shape of mouse 595 in epoch stim contained too few rows.\ndF/F shape of mouse 596 in epoch stim contained too few rows.\ndF/F shape of mouse 648 in epoch spont contained too few rows.\ndF/F shape of mouse 648 in epoch stim contained too few rows.\ndF/F shape of mouse 648 in epoch all contained too few rows.\ndF/F shape of mouse 650 in epoch spont contained too few rows.\ndF/F shape of mouse 650 in epoch stim contained too few rows.\ndF/F shape of mouse 650 in epoch all contained too few rows.\n"
    }
   ],
   "source": [
    "fxs_wt = {'FXS': {'spont': {}, 'stim': {}, 'all': {}}, 'WT': {'spont': {}, 'stim': {}, 'all': {}}}\n",
    "epochs = ('spont', 'stim', 'all')\n",
    "\n",
    "for mouse_id, ds in data.groupby('mouse_id'):\n",
    "    for epoch in epochs:\n",
    "        try:\n",
    "            dff = filter_da(ds, epoch)\n",
    "            if dff.shape[0] < 10:\n",
    "                print(f\"dF/F shape of mouse {mouse_id} in epoch {epoch} contained too few rows.\")\n",
    "                continue\n",
    "            condition = str(ds.condition[0].values)\n",
    "            mean_dff = dff_analysis.calc_mean_dff(dff)\n",
    "            mean_spike_rate = dff_analysis.calc_mean_spike_num(dff, fps=ds.attrs['fps'], thresh=0.70)      \n",
    "            mean_dff_no_bg = dff_analysis.calc_mean_dff_no_background(dff)\n",
    "            mean_spike_rate_no_bg = dff_analysis.calc_mean_spike_num_no_background(dff, fps=ds.attrs['fps'], thresh=0.70)\n",
    "            fxs_wt[condition][epoch][mouse_id] = {\n",
    "                'mean_dff': mean_dff, \n",
    "                'mean_spike_rate': mean_spike_rate, \n",
    "                'mean_dff_no_bg': mean_dff_no_bg, \n",
    "                'mean_spike_rate_no_bg': mean_spike_rate_no_bg\n",
    "            }\n",
    "        except AssertionError:  # some mice don't have all epochs\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "FXS mice: dict_keys(['517', '518', '609', '614', '647'])\nWT mice: dict_keys(['595', '596', '615', '640', '674'])\n"
    }
   ],
   "source": [
    "print(f\"FXS mice: {fxs_wt['FXS']['all'].keys()}\")\n",
    "print(f\"WT mice: {fxs_wt['WT']['all'].keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fname.with_suffix('.p'), 'wb') as f:\n",
    "    pickle.dump(fxs_wt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for geno, genodata in fxs_wt.items():\n",
    "    for epoch, epochdata in genodata.items():\n",
    "        for mid, midata in epochdata.items():\n",
    "            for measure, measurement in midata.items():\n",
    "                df_list.append(pd.DataFrame({'Epoch': epoch, 'Genotype': geno, 'MouseID': mid, 'Measure': measure, 'Value': measurement}))\n",
    "                \n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = ('mean_dff', 'mean_spike_rate', 'mean_dff_no_bg', 'mean_spike_rate_no_bg')\n",
    "\n",
    "for epoch in epochs:\n",
    "    for measure in measures:\n",
    "        cur_data = df.query(f'Epoch == \"{epoch}\" and Measure == \"{measure}\"')\n",
    "        cur_data.loc[:, ['Genotype', 'MouseID', 'Value']].to_csv(fname.with_name(f'epoch_{epoch}_measure_{measure}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('ca_analysis': conda)",
   "language": "python",
   "name": "python37364bitcaanalysisconda0e7d26eec6ef4f979f92fdcb8b54eff4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}